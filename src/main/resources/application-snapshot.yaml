#debug: true
custom:
  kafka:
    topics:
      stats: stats
      linear-acceleration: linear_acceleration
      accelerometer: accelerometer
      gyroscope: gyroscope
      light: light

spring:
  security:
    user:
      name: ${USERNAME}
      password: ${PASSWORD}
      roles: ADMINISTRATOR
  cloud:
    stream:
      bindings:
        input:
          contentType: application/*+avro
          consumer:
            useNativeDecoding: true
        output:
          producer:
            useNativeEncoding: true
        # Configure the bindings
        linear-acceleration:
          destination: ${custom.kafka.topics.linear-acceleration}
        accelerometer:
          destination: ${custom.kafka.topics.accelerometer}
        gyroscope:
          destination: ${custom.kafka.topics.gyroscope}
        light:
          destination: ${custom.kafka.topics.light}
        stats:
          destination: ${custom.kafka.topics.stats}
      # Native Encoding enables the kafka serialization/deserialization
      default.producer:
        useNativeEncoding: true
      default.consumer:
        useNativeEncoding: true

      #TODO: figure out how to handle different types. maybe use connector to stream in format <key: timestamp, value: json>
      #TODO: ...so that the bindings can be configured for a single serializer/deserializer for all streams.
      kafka:
        streams:
          # Configure the kafka streams binder to consume messages
          binder:
            brokers: kafka:29092
            configuration:
              # TODO: use native encoding (is it used already?)
              default.key.serde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
              default.value.serde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
              schema.registry.url: http://schema-registry:8081
              cache.max.bytes.buffering: 0
          bindings:
            sensor-data:
              consumer.application-id: indicator-service

